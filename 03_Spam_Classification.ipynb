{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anson3208/Sentiment-Textmining-Analysis-Learning/blob/main/03_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 Spam Classification\n"
      ],
      "metadata": {
        "id": "gnue4wBGGdAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMS SPAM Collection"
      ],
      "metadata": {
        "id": "iu0A5GzWYSKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SMS SPAM Collection is a corpus of real text messages (SMS messages) that have been classified as either SPAM or HAM (i.e. not SPAM). The corpus contains 5,574 documents, 747 of which are SPAM and 4,827 of which are HAM. You can find the readme for the corpus [here](https://storage.googleapis.com/wd13/SMSSpamCollectionReadme). "
      ],
      "metadata": {
        "id": "aYD73eRqblOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code downloads a copy of the SMS SPAM Corpus and saves it in a variable `sms_corpus`. "
      ],
      "metadata": {
        "id": "RkwZzYJrf4Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request, json \n",
        "sms_corpus = []\n",
        "with urllib.request.urlopen(\"https://storage.googleapis.com/wd13/SMSSpamCollection.txt\") as url:\n",
        "  for line in url.readlines():\n",
        "    sms_corpus.append(line.decode().split('\\t'))"
      ],
      "metadata": {
        "id": "JVwy5gnFYSVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sms_corpus` is a list. Each element of the list is another list which stores a document and its label."
      ],
      "metadata": {
        "id": "ejA8KxjOgO1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print the text and label of document 16\n",
        "docid = 16\n",
        "print(sms_corpus[docid])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xppAWdKJgRD3",
        "outputId": "a971f399-e621-4ca6-fdb4-a4c0a7846efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ham', \"Oh k...i'm watching here:)\\n\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the label of document 16\n",
        "docid = 16\n",
        "print(sms_corpus[docid][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujCCOXJFmp6o",
        "outputId": "57841ded-645d-49f2-b612-4afcefb28804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the text of document 16\n",
        "docid = 16\n",
        "print(sms_corpus[docid][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heI9vtSzmqHT",
        "outputId": "c5d2273a-98ec-46ee-fa7b-6b05e6c14376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh k...i'm watching here:)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a tokenizer"
      ],
      "metadata": {
        "id": "kuihr-nKCrq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function `tokenize` that takes a string and returns a list of tokens. "
      ],
      "metadata": {
        "id": "6l-a_brkP2c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request, json \n",
        "with urllib.request.urlopen(\"https://storage.googleapis.com/wd13/stopwords%20and%20lemmas.json\") as url: #import the a dictionary of words as url-->to include lemma and stopwords\n",
        "  data = json.load(url) #the data in url has no datatype-->use json.load to load the data as dictionary\n",
        "  stopwords = data['stopwords'] #the link is a dictionary format, stopwords is the key which store the list of words that should be excluded\n",
        "\n",
        "\n",
        "import re\n",
        "def tokenize(doc):\n",
        "  emoti_list = [':)','(:',':(','):',':D','D:',':P','P:',':V','V:',':/','/:',':\\\\','\\\\:',':|','|:',\n",
        "                ';)','(;',';(',');',';D','D;',';P','P;',';V','V;',';/','/;',';\\\\','\\\\;',';|','|;',\n",
        "                ':-)','(-:',':-(',')-:',':-D','D-:',':-P','P-:',':-V','V-:',':-/','/-:',':-\\\\',\n",
        "                '\\\\-:',':-|','|-:',';-)','(-;',';-(',')-;',';-D','D-;',';-P','P-;',';-V','V-;',\n",
        "                ';-/','/-;',';-\\\\','\\\\-;',';-|','|-;']\n",
        "  tokenizer_pattern = re.compile('|'.join([\n",
        "      '|'.join([re.escape(e) for e in emoti_list]),\n",
        "      \"[A-Za-z]+(?:['-_\\.][A-Za-z]+)?\",\n",
        "      '\\.\\.+'\n",
        "      ]))\n",
        "  tokens = tokenizer_pattern.findall(doc)\n",
        "  for i in range(0,len(tokens)):\n",
        "    if re.match('\\.\\.+',tokens[i]):\n",
        "      tokens[i] = '..+'\n",
        "    else:\n",
        "      tokens[i] = tokens[i].lower()\n",
        "  return(tokens)"
      ],
      "metadata": {
        "id": "Jgg8XrkhC1CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import log function"
      ],
      "metadata": {
        "id": "hzNSjeBLHA-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "log(1)"
      ],
      "metadata": {
        "id": "BoHVDK-qHC1Z",
        "outputId": "2180486d-a107-42e9-c675-edc742d152ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate token scores"
      ],
      "metadata": {
        "id": "dxttX-SIh1oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate scores for every token in the corpus, using the method discussed in class. Store these scores in a dictionary called `token_scores`. "
      ],
      "metadata": {
        "id": "1D5FlYbhi5lJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Blank set\n",
        "\n",
        "corpus_ham_count = 0\n",
        "corpus_spam_count = 0\n",
        "token_ham_count = {}\n",
        "token_spam_count = {}\n",
        "unique_token_count = set()\n",
        "token_score={}\n",
        "\n",
        "\n",
        "\n",
        "for doc in sms_corpus:        #for each doc, the output is ['ham', 'abc']\n",
        "  label = doc[0]              #Create variable label represets 'ham' or 'spam'\n",
        "  tokens = tokenize(doc[1])   #tokenize document\n",
        "\n",
        "#Counting number of ham and spam in corpus\n",
        "  if label == 'ham':\n",
        "    corpus_ham_count += 1\n",
        "  else:\n",
        "    corpus_spam_count += 1    \n",
        "  \n",
        "#counting token\n",
        "  for token in set(tokens):               #turn token list to be set to have unique tokens\n",
        "    unique_token_count.add(token)         #adding token to unique token set\n",
        "    if label == 'ham':\n",
        "      if token not in token_ham_count:\n",
        "        token_ham_count[token] =1\n",
        "      else:\n",
        "        token_ham_count[token] +=1\n",
        "    else:\n",
        "      if token not in token_spam_count:\n",
        "        token_spam_count[token] =1\n",
        "      else:\n",
        "        token_spam_count[token] +=1\n",
        "\n",
        "#calculating score\n",
        "for token in unique_token_count:\n",
        "  if token not in token_spam_count or token not in token_ham_count:\n",
        "    continue\n",
        "  token_score[token] = log((token_spam_count[token]/corpus_spam_count)/(token_ham_count[token]/corpus_ham_count))\n",
        "\n",
        "\n",
        "#score of document(p|spam / p|ham)\n",
        "total_count = corpus_ham_count + corpus_spam_count\n",
        "prob_ham = corpus_ham_count/total_count\n",
        "prob_spam = corpus_spam_count/total_count\n",
        "\n",
        "score = log(prob_spam/prob_ham)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-Sco6VTnfVkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTLmfI-iDJYd",
        "outputId": "5e976690-b060-46f5-cc64-ae6cbdfe0ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.8659152505276757"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_score['go']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjk8RAH38lqp",
        "outputId": "28b976e3-f4bf-4b0b-98d6-7a6578ee3754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.09289830336354553"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a score message function"
      ],
      "metadata": {
        "id": "e6rrKlK0kY77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a funciton `score_message` that takes an SMS message `doc` and returns a SPAM score, using the method discussed in class. "
      ],
      "metadata": {
        "id": "jn6rOE5JnPqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_message(doc):\n",
        "  score = log(corpus_spam_count/corpus_ham_count)\n",
        "  tokens = tokenize(doc)\n",
        "  for token in set(tokens):\n",
        "    if token in token_score:\n",
        "      score = score + token_score[token]\n",
        "  return(score)"
      ],
      "metadata": {
        "id": "ss48vDhckZMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Score some messages"
      ],
      "metadata": {
        "id": "74ygWoHMALmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score_message('go hello')"
      ],
      "metadata": {
        "id": "BcE0HJxgALxk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2476cd5f-35c0-44c9-d8b6-e82eae3d828c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.3954833963575908"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion"
      ],
      "metadata": {
        "id": "ietSm--hqKSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What tokens are most predictive of a message being SPAM?"
      ],
      "metadata": {
        "id": "e-tCh_U8qMg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the max value in token_score\n",
        "#print(f'The token \"{max(token_score, key=token_score.get)}\" has the highest likelihood being SPAM message')\n",
        "\n",
        "for token,score in sorted(token_score.items(),key=lambda item: -item[1])[0:20]:\n",
        "  print(token,score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiIzxYtqfMiq",
        "outputId": "b447c02b-4df8-4425-efda-df8fadc57b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code 5.267112632189831\n",
            "p 5.267112632189831\n",
            "uk 5.0439690808756215\n",
            "urgent 4.894437346904658\n",
            "award 4.861647524081667\n",
            "delivery 4.861647524081667\n",
            "await 4.810354229694116\n",
            "private 4.756287008423841\n",
            "nokia 4.737594875411688\n",
            "services 4.699128594583891\n",
            "club 4.638503972767457\n",
            "landline 4.638503972767457\n",
            "statement 4.638503972767457\n",
            "voucher 4.573965451629886\n",
            "apply 4.573965451629886\n",
            "games 4.573965451629886\n",
            "mths 4.573965451629886\n",
            "rate 4.504972580142934\n",
            "congratulations 4.504972580142934\n",
            "service 4.468604935972059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What tokens are most predictive of a message being HAM?"
      ],
      "metadata": {
        "id": "sdVgBhPEopTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token,score in sorted(token_score.items(),key=lambda item: item[1])[0:20]:\n",
        "  print(token,score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwno693ZgEPi",
        "outputId": "7f3a39ae-a6d9-41cb-9845-a2fd7306f1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "da -3.0244338776940785\n",
            "oh -2.825432631701468\n",
            "come -2.811575597040042\n",
            "much -2.7975238435843917\n",
            "too -2.76881373770196\n",
            "way -2.6984329409401604\n",
            "wat -2.677379531742328\n",
            "already -2.6114215639505307\n",
            "say -2.599992868126908\n",
            "happy -2.564901548315638\n",
            "yeah -2.564901548315638\n",
            "really -2.5408039967365776\n",
            "home -2.509841771132611\n",
            "..+ -2.3246303601545515\n",
            "his -2.261219134517416\n",
            "thing -2.2449586136456356\n",
            "i've -2.2449586136456356\n",
            "but -2.201889756459813\n",
            "did -2.1414179347047955\n",
            "my -2.1347844112091616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many documents are mis-classified by the model?"
      ],
      "metadata": {
        "id": "eX-EH7m9otIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ham_correct_count = 0\n",
        "spam_correct_count = 0\n",
        "ham_mis_count = 0\n",
        "spam_mis_count = 0\n",
        "\n",
        "for doc in sms_corpus:\n",
        "  label = doc[0]\n",
        "  score = score_message(doc[1])\n",
        "  if label == 'ham':\n",
        "    if score >0:\n",
        "      ham_mis_count += 1\n",
        "    else:\n",
        "      ham_correct_count +=1\n",
        "  else:\n",
        "    if score <0:\n",
        "      spam_mis_count +=1\n",
        "    else:\n",
        "      spam_correct_count +=1\n",
        "print(f'Number of Ham mis-classifed: {ham_mis_count}')\n",
        "print(f'Number of Ham correct-classifed: {ham_correct_count}')\n",
        "print(f'Number of Spam mis-classifed: {spam_mis_count}')\n",
        "print(f'Number of Spam correct-classifed: {spam_correct_count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dwtkSSMMKbU",
        "outputId": "350ff073-e687-46b8-f8b1-bf0bfa120be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Ham mis-classifed: 448\n",
            "Number of Ham correct-classifed: 4379\n",
            "Number of Spam mis-classifed: 13\n",
            "Number of Spam correct-classifed: 734\n"
          ]
        }
      ]
    }
  ]
}